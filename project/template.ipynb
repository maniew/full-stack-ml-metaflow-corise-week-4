{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Full Stack Machine Learning's Week 4 Project!\n",
    "\n",
    "In the final week, you will return to the workflow you built last week on the [taxi dataset](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Deploy the champion\n",
    "Use what you have learned in the last two weeks to make necessary modifications and to deploy your latest version of the `TaxiFarePrediction` flow to Argo. Use `--branch champion` to denote this deployment as the champion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../flows/cloud/taxifare_linear_regression.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../flows/cloud/taxifare_linear_regression.py\n",
    "from metaflow import FlowSpec, step, card, conda_base, current, Parameter, Flow, project\n",
    "from metaflow.cards import Markdown, Table, Image, Artifact\n",
    "\n",
    "URL = \"https://outerbounds-datasets.s3.us-west-2.amazonaws.com/taxi/latest.parquet\"\n",
    "DATETIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "@conda_base(libraries={'pandas': '1.4.2', 'pyarrow': '11.0.0', 'numpy': '1.21.2', 'scikit-learn': '1.1.2'})\n",
    "@project(name='taxifare')\n",
    "class TaxiFarePrediction(FlowSpec):\n",
    "\n",
    "    data_url = Parameter(\"data_url\", default=URL)\n",
    "\n",
    "    def transform_features(self, df):\n",
    "\n",
    "        # TODO: \n",
    "            # Try to complete tasks 2 and 3 with this function doing nothing like it currently is.\n",
    "            # Understand what is happening.\n",
    "            # Revisit task 1 and think about what might go in this function.\n",
    "        obviously_bad_data_filters = [\n",
    "            df.fare_amount > 0,         # fare_amount in US Dollars\n",
    "            df.trip_distance <= 100,    # trip_distance in miles\n",
    "            df.trip_distance > 0,\n",
    "            df.payment_type <= 2,\n",
    "            df.passenger_count > 0,\n",
    "            df.airport_fee > 0,\n",
    "            df.total_amount > 0\n",
    "        ]\n",
    "\n",
    "        for f in obviously_bad_data_filters:\n",
    "            df = df[f] \n",
    "        return df\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "\n",
    "        import pandas as pd\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        self.df = self.transform_features(pd.read_parquet(self.data_url))\n",
    "\n",
    "        # NOTE: we are split into training and validation set in the validation step which uses cross_val_score.\n",
    "        # This is a simple/naive way to do this, and is meant to keep this example simple, to focus learning on deploying Metaflow flows.\n",
    "        # In practice, you want split time series data in more sophisticated ways and run backtests. \n",
    "        self.X = self.df[\"trip_distance\"].values.reshape(-1, 1)\n",
    "        self.y = self.df[\"total_amount\"].values\n",
    "        self.next(self.linear_model)\n",
    "\n",
    "    @step\n",
    "    def linear_model(self):\n",
    "        \"Fit a single variable, linear model to the data.\"\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "\n",
    "        # TODO: Play around with the model if you are feeling it.\n",
    "        self.model = LinearRegression()\n",
    "\n",
    "        self.next(self.validate)\n",
    "\n",
    "    def gather_sibling_flow_run_results(self):\n",
    "\n",
    "        # storage to populate and feed to a Table in a Metaflow card\n",
    "        rows = []\n",
    "\n",
    "        # loop through runs of this flow \n",
    "        for run in Flow(self.__class__.__name__):\n",
    "            if run.id != current.run_id:\n",
    "                if run.successful:\n",
    "                    icon = \"‚úÖ\" \n",
    "                    msg = \"OK\"\n",
    "                    score = str(run.data.scores.mean())\n",
    "                else:\n",
    "                    icon = \"‚ùå\"\n",
    "                    msg = \"Error\"\n",
    "                    score = \"NA\"\n",
    "                    for step in run:\n",
    "                        for task in step:\n",
    "                            if not task.successful:\n",
    "                                msg = task.stderr\n",
    "                row = [Markdown(icon), Artifact(run.id), Artifact(run.created_at.strftime(DATETIME_FORMAT)), Artifact(score), Markdown(msg)]\n",
    "                rows.append(row)\n",
    "            else:\n",
    "                rows.append([Markdown(\"‚úÖ\"), Artifact(run.id), Artifact(run.created_at.strftime(DATETIME_FORMAT)), Artifact(str(self.scores.mean())), Markdown(\"This run...\")])\n",
    "        return rows\n",
    "                \n",
    "    \n",
    "    @card(type=\"corise\")\n",
    "    @step\n",
    "    def validate(self):\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        self.scores = cross_val_score(self.model, self.X, self.y, cv=5)\n",
    "        current.card.append(Markdown(\"# Taxi Fare Prediction Results\"))\n",
    "        current.card.append(Table(self.gather_sibling_flow_run_results(), headers=[\"Pass/fail\", \"Run ID\", \"Created At\", \"R^2 score\", \"Stderr\"]))\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        print(\"Success!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TaxiFarePrediction()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Build the challenger\n",
    "Develop a second model, by using the same `TaxiFarePrediction` architecture. Then, deploy the flow to Argo as the `--branch challenger`. \n",
    "<br>\n",
    "<br>\n",
    "Hint: Modify the `linear_model` step. \n",
    "<br>\n",
    "Bonus: Write a paragraph summary of how you developed the second model and tested it before deploying the challenger flow. Let us know in Slack what you found challenging about the task? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Analyze the results\n",
    "Return to this notebook, and read in the results of the challenger and champion flow using the Metaflow Client API.\n",
    "<br><br>\n",
    "\n",
    "#### Questions\n",
    "- Does your model perform better on the metrics you selected? \n",
    "- Think about your day job, how would you go about assessing whether to roll forward the production \"champion\" to your new model? \n",
    "    - What gives you confidence one model is better than another?\n",
    "    - What kinds of information do you need to monitor to get buy-in from stakeholders that model A is preferable to model B?  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONGRATULATIONS! üéâ‚ú®üçæ\n",
    "If you made it this far, you have completed the Full Stack Machine Learning Corise course. \n",
    "We are so glad that you chose to learn with us, and hope to see you again in future courses. Stay tuned for more content and come join us in [Slack](http://slack.outerbounds.co/) to keep learning about Metaflow!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full-stack-metaflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
